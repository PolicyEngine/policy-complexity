{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from policyengine_us import Microsimulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Microsimulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sim.calculate(\"household_net_income\". period = 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sim.calculate_dataframe([\"household_market_income\", \"household_net_income\", \"household_size\", \"tax_unit_dependents\", \"household_weight\"], period = 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)\n",
    "help(microdf.generic.MicroDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['household_net_income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1 = pd.DataFrame(df)\n",
    "# df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.sample(n = int(sum(df[\"household_weight\"])), \n",
    "                 weights = df[\"household_weight\"], \n",
    "                 random_state = 1,\n",
    "                 replace = True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_2.shape[0] % 2 == 0:\n",
    "    df_2 = df_2\n",
    "else:\n",
    "    df_2 = df_2.drop(df_2.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe\n",
    "\n",
    "# // is the floor division operator\n",
    "half_index = df_2.shape[0] // 2\n",
    "\n",
    "df_2 = df_2.reset_index(drop=True)\n",
    "\n",
    "df_2 = pd.concat([\n",
    "    # .iloc[:x] selects all rows from the beginning up to, but not including, the row at position x\n",
    "        df_2.iloc[:half_index], \n",
    "        df_2.iloc[half_index:]\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_2.shape[1]\n",
    "df_2.columns\n",
    "\n",
    "new_column_names = [\"y\", \"y_minus_T\", \"A\", \"A_minus_a\", \"w\"]\n",
    "\n",
    "column_names_j = []\n",
    "for j in new_column_names:\n",
    "    new_name = str(j) + \"_j\"\n",
    "    column_names_j.append(new_name)\n",
    "\n",
    "column_names_i = []\n",
    "for i in new_column_names:\n",
    "    new_name = str(i) + \"_i\"\n",
    "    column_names_i.append(new_name)\n",
    "\n",
    "df_2.columns = column_names_i + column_names_j\n",
    "\n",
    "df_2['I'] = np.where(\n",
    "    (df_2['y_i'] - df_2['y_minus_T_i']) > (df_2['y_j'] - df_2['y_minus_T_j']),\n",
    "    1, 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as optim\n",
    "from scipy.stats import norm\n",
    "from numpy import log\n",
    "\n",
    "# def neg_log_likelihood(params, data):\n",
    "#       tau, theta, sigma = params\n",
    "#       cdf = norm.cdf(\n",
    "#           (tau * np.log(data['y_i']/data['y_j'])\n",
    "#            + np.log((data['A_i'] - data['A_minus_a_i']) / (data['A_j'] - data['A_minus_a_j']))\n",
    "#            + theta * np.log(data['A_i'] / data['A_j'])\n",
    "#           )/ (np.power(2, 1/2)*sigma)\n",
    "#       )\n",
    "#       log_likelihood = np.sum(\n",
    "#             data['I'] * np.log(cdf) + (1 - data['I']) * np.log(1 - cdf)\n",
    "#             )\n",
    "#       return -log_likelihood\n",
    "\n",
    "# norm.cdf()\n",
    "\n",
    "# initial_params = [0.6, 1, 5]\n",
    "\n",
    "# result = optim.minimize(neg_log_likelihood, initial_params, args = (df_2,))\n",
    "\n",
    "# def neg_log_likelihood(params, data):\n",
    "#       tau, theta, sigma = params\n",
    "#       y_i, y_j = data['y_i'], data['y_j']\n",
    "#       A_i, A_j = data['A_i'], data['A_j']\n",
    "#       a_i = A_i - data['A_minus_a_i']\n",
    "#       a_j = A_j - data['A_minus_a_j']\n",
    "#       I = data['I']\n",
    "\n",
    "#       cdf = norm.cdf(\n",
    "#             (tau * np.log(y_i / y_j)\n",
    "#             + np.log(a_i / a_j)\n",
    "#             + theta * np.log(A_i / A_j)\n",
    "#             ),\n",
    "#             scale = pow(2, 1/2) * sigma\n",
    "#       )\n",
    "#       log_likelihood = np.sum(\n",
    "#             I * np.log(cdf) + (1 - I) * np.log(1 - cdf)\n",
    "#             )\n",
    "#       return -log_likelihood\n",
    "\n",
    "# initial_params = [0.6, 1, 5]\n",
    "\n",
    "# result = optim.minimize(neg_log_likelihood, initial_params, args = (df_2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(params, data):\n",
    "      tau, theta, sigma = params\n",
    "      y_i, y_j = data['y_i'], data['y_j']\n",
    "      A_i, A_j = data['A_i'], data['A_j']\n",
    "      a_i = A_i - data['A_minus_a_i']\n",
    "      a_j = A_j - data['A_minus_a_j']\n",
    "      I = data['I']\n",
    "\n",
    "      # Calculate the utility function components\n",
    "      utility = (tau * np.log(y_i / y_j)\n",
    "            + np.log(a_i / a_j)\n",
    "            + theta * np.log(A_i / A_j))\n",
    "\n",
    "      # Correct way to use norm.cdf with scale parameter\n",
    "      scaled_utility = utility / (np.sqrt(2) * sigma)\n",
    "      cdf = norm.cdf(scaled_utility)\n",
    "\n",
    "      # Handle potential numerical issues with log(0) or log(1)\n",
    "      cdf = np.clip(cdf, 1e-10, 1-1e-10)\n",
    "\n",
    "      log_likelihood = np.sum(\n",
    "            I * np.log(cdf) + (1 - I) * np.log(1 - cdf)\n",
    "            )\n",
    "      return -log_likelihood\n",
    "\n",
    "initial_params = [0.6, 1, 5]\n",
    "\n",
    "result = optim.minimize(neg_log_likelihood, initial_params, args = (df_2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
